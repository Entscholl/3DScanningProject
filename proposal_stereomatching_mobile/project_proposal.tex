\documentclass[a4paper,pagesize 10pt]{scrartcl}

\usepackage{graphicx}
\usepackage{scalefnt}
\usepackage{textfit}

\begin{document}


\begin{center}{\Huge\textbf{Project Proposal}}\end{center}
\begin{center}{\Large\textbf{''YOUR TITLE''}}\end{center}

\section{Abstract}

%
%Write a short abstract of your planned project.
%
%Cite papers that you want to use as references (e.g. Adelson et al.~\cite{adelson1984pyramid}).
%
%Include an overview figure that shows your planned processing pipeline.
%
%
The problem of feature detection is well known and studied, but can be computationally expensive. In this project, we study feature detection systems, which are able to run on a mobile phone. 

The resulting set of features and the data from the built in-accelerometers will then be used to calculate the depth of each feature in the frames using stereo matching [CITATION NEEDED].
% Camera calibration for intrinsic parameters necessary, e.g. OpenCV

First, we detect and match features between the two RGB images to obtain the epipolar geometry.[CITATION NEEDED]
%Still not sure how that is exactely done
%Sparse feature matching maybe? e.g. SIFT, SURF, ORB
Once we have the epipolar geometry, we can rectify the images ~\cite{loop1999}. Once rectified we can apply stereo matching algorithms e.g. PatchMatch ~\cite{Bleyer2011} or PM-Huber ~\cite{Heise2013} to calculate the displacement map. In the optimal parallel case we can calculate the depth via triangulation [CITATION NEEDED]. 
%it's described in the lecture slides and on stack overflow that way. Have to find a paper though.

The inertial data of the accelerometer is integrated twice to obtain the positional difference~\cite{Seifert2007}. Here, the numerical integration error accumulates over time. In contrast, the rotational difference between to RGB data sets is obtained by sampling the gyroscope sensor. We test if the supplied commodity sensors are accurate enough to augment the image rectification.

With this depth information, we are able to apply advanced image processing algorithms e. g. a Bokeh effect ~\cite{Lee2008}.

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=\linewidth]{overview}
%	\caption{Method overview.}
%	\label{fig:overview}
%\end{figure}
%								Sensor Data	A
%									 ||
%Figure: Picture A => Epipolar Lines => Rectify \
%												 => Disparity Map => Depth => Bokeh	
%		 Picture B => Epipolar Lines => Rectify /
%									 ||
%								Sensor Data B

\section{Requirements}
List your hardware requirements. E.g. Kinect sensor, Webcam, etc..
%Possibly a Smartphone with Stereo Capabilites, P30

\section{Team}



% references
{\small
	\bibliographystyle{plain}
	\bibliography{project_proposal}
}

\end{document}


